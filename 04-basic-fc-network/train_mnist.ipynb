{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import transforms\n",
    "from models.classifier import ClassifierForMNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "ETA = 1e-3\n",
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(ps, labels):\n",
    "    topk_vals, topk_indices = ps.topk(k=1, dim=1)\n",
    "    equality = (topk_indices.squeeze() == labels).float()\n",
    "    acc = equality.mean()\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(context, x, y):\n",
    "    model = context[\"model\"]\n",
    "    optimizer = context[\"optimizer\"]\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    N = x.size(0)\n",
    "    x = x.view(N, -1)\n",
    "    \n",
    "    logps = model(x)\n",
    "    loss = F.nll_loss(logps, y.long()) # nn.NLLLoss()(ps, y) 와 같음\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    ps = torch.exp(logps)\n",
    "    acc = compute_accuracy(ps, y.long())\n",
    "    \n",
    "    return loss.item(), acc.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_step(context, x, y):\n",
    "    model = context[\"model\"]\n",
    "    \n",
    "    N = x.size(0)\n",
    "    x = x.view(N, -1)\n",
    "    \n",
    "    logps = model(x)\n",
    "    loss = F.nll_loss(logps, y.long()) # nn.NLLLoss()(ps, y) 와 같음\n",
    "    \n",
    "    ps = torch.exp(logps)\n",
    "    acc = compute_accuracy(ps, y.long())\n",
    "    \n",
    "    return loss.item(), acc.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (1.0,))\n",
    "    ])\n",
    "    \n",
    "    trainset = MNIST(\"../data\", transform=transform, download=False, train=True)\n",
    "    train_loader = DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    \n",
    "    testset = MNIST(\"../data\", transform=transform, download=False, train=False)\n",
    "    test_loader = DataLoader(testset, batch_size=BATCH_SIZE)\n",
    "    \n",
    "    model = ClassifierForMNIST().cuda()\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "    \n",
    "    context = {\n",
    "        \"model\": model,\n",
    "        \"optimizer\": optimizer\n",
    "    }\n",
    "    \n",
    "    for e in range(EPOCHS):\n",
    "        train_loss = 0.0\n",
    "        train_acc = 0.0\n",
    "        test_loss = 0.0\n",
    "        test_acc = 0.0\n",
    "        \n",
    "        model.train()\n",
    "        \n",
    "        for x, y in train_loader:\n",
    "            x = x.cuda()\n",
    "            y = y.float().cuda()\n",
    "            \n",
    "            loss, acc = train_step(context, x, y)\n",
    "            train_loss += loss\n",
    "            train_acc += acc\n",
    "            \n",
    "        model.eval()\n",
    "            \n",
    "        for x, y in test_loader:\n",
    "            x = x.cuda()\n",
    "            y = y.float().cuda()\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                loss, acc = eval_step(context, x, y)\n",
    "                test_loss += loss\n",
    "                test_acc += acc\n",
    "                \n",
    "        train_loss /= len(train_loader)\n",
    "        train_acc /= len(train_loader)\n",
    "        test_loss /= len(test_loader)\n",
    "        test_acc /= len(test_loader)\n",
    "        \n",
    "        print(f\"Epochs {e+1}/{EPOCHS}\")\n",
    "        print(f\"Train loss: {train_loss:.8f}, train acc: {train_acc:.4f}\")\n",
    "        print(f\"Test loss: {test_loss:.8f}, test acc: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs 1/10\n",
      "Train loss: 0.47414244, train acc: 0.8632\n",
      "Test loss: 0.27440646, test acc: 0.9179\n",
      "Epochs 2/10\n",
      "Train loss: 0.23155058, train acc: 0.9311\n",
      "Test loss: 0.17523321, test acc: 0.9478\n",
      "Epochs 3/10\n",
      "Train loss: 0.16979344, train acc: 0.9493\n",
      "Test loss: 0.14936868, test acc: 0.9532\n",
      "Epochs 4/10\n",
      "Train loss: 0.13020549, train acc: 0.9602\n",
      "Test loss: 0.11907259, test acc: 0.9633\n",
      "Epochs 5/10\n",
      "Train loss: 0.10879804, train acc: 0.9669\n",
      "Test loss: 0.10857096, test acc: 0.9663\n",
      "Epochs 6/10\n",
      "Train loss: 0.09262586, train acc: 0.9711\n",
      "Test loss: 0.09888093, test acc: 0.9698\n",
      "Epochs 7/10\n",
      "Train loss: 0.08060006, train acc: 0.9747\n",
      "Test loss: 0.09167872, test acc: 0.9721\n",
      "Epochs 8/10\n",
      "Train loss: 0.07117876, train acc: 0.9783\n",
      "Test loss: 0.08615670, test acc: 0.9722\n",
      "Epochs 9/10\n",
      "Train loss: 0.06306767, train acc: 0.9801\n",
      "Test loss: 0.09740640, test acc: 0.9699\n",
      "Epochs 10/10\n",
      "Train loss: 0.06005674, train acc: 0.9807\n",
      "Test loss: 0.08176941, test acc: 0.9744\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
